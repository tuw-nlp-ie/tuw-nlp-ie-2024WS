{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Semantics: an introduction\n",
    "\n",
    "### Natural Language Processing and Information Extraction,  2024WS\n",
    "Lecture 7, 12/6/2024\n",
    "\n",
    "GÃ¡bor Recski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This material can be downloaded from [https://github.com/tuw-nlp-ie/tuw-nlp-ie-2024WS](https://github.com/tuw-nlp-ie/tuw-nlp-ie-2024WS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SLP3 relevant chapters\n",
    "\n",
    "[Appendix F](https://web.stanford.edu/~jurafsky/slp3/F.pdf) (Logical Representations of Sentence Meaning, Chapter 19 in 2023)\n",
    "\n",
    "Chapter X (Computational Semantics and Semantic Parsing) - was planned as Chapter 2020 until 2023, now removed\n",
    "\n",
    "[Appendix G](https://web.stanford.edu/~jurafsky/slp3/G.pdf) (Word Senses and WordNet, Chapter 23 in 2023)\n",
    "\n",
    "[Chapter 21](https://web.stanford.edu/~jurafsky/slp3/21.pdf) (Semantic Role Labeling and Argument Structure, Chapter 24 in 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- word structure\n",
    "- phrase structure\n",
    "- sentence structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What's missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![np](np2_70.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![elephant](elephant.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLP is good at avoiding semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![mt](mt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![qa](qa.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![rte](rte.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coreference resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_The trophy doesn't fit into the brown suitcase because it's too small._\n",
    "\n",
    "What is too small?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_The trophy doesn't fit into the brown suitcase because it's too large._\n",
    "\n",
    "What is too large?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Winograd challenge](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WSCollection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to represent meaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"simba.jpg\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "_\"I think we are pretty far away from having a system that can engage in a dialogue with another person like a person could.\"_\n",
    "\n",
    "_\"Neural networks are a really incredibly powerful hammer, and sometimes I wonder if we are just looking for nails.\"_\n",
    "\n",
    "_\"it would be really cool if a couple of smart linguists would go back to semantics\"_\n",
    "\n",
    "Alexander Koller in a [2021 interview](https://link.springer.com/article/10.1007/s13218-021-00718-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "See also [Bender & Koller 2020](https://aclanthology.org/2020.acl-main.463.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What can be expected of a theory of semantics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_\"A semantic theory describes and explains the interpretative ability of speakers by accounting for their performance in determining the number and content of the readings of a sentence, by detecting semantic anomalies, by deciding on paraphrase relations between sentences, and by marking every other semantic property or relation that plays a role in this ability.\"_\n",
    "\n",
    "[(Katz & Fodor 1963)](https://www.jstor.org/stable/411200?seq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"saeed_70.jpg\" width=\"800\"/>\n",
    "</div>\n",
    "\n",
    "[Saeed, J. (2003): Semantics (Introducing Linguistics)](https://www.wiley.com/en-us/Semantics%2C+4th+Edition-p-9781118430163)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_\"The study of discussing the meaning/interpretation of words or groups of\n",
    "words within a certain context; usually in order to win some form of argument.\"_\n",
    "\n",
    "[(Urban Dictionary)](https://www.urbandictionary.com/define.php?term=semantics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributional models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   - semantic representations are __real-valued vectors__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- vectors are constructed from large corpora, with the objective that Euclidean distance is proportional to distributional similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- that this is a representation of semantics is based on the _Distributional Hypothesis_: that words appearing in similar contexts are similar in meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Distributional representations are also called __word embeddings__ and are currently __used in virtually all state-of-the-art NLP systems__ to represent word meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- very little is known about __the structure of these representations__. This makes it very hard to understand __why they work__, or why they don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vector-based solutions of NLP tasks are especially **prone to bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As language models, they are only good for imitating language, not actually using it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logical semantics\n",
    "<a id='13.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Semantic representations are logical formulae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- \\>90% of semantics research in the field of theoretical linguistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First-order logic\n",
    "\n",
    "(FOL, a.k.a. predicate logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - predicates have __arguments__, which are entities\n",
    "  - __quantification__ over entities w.r.t predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - _John is eating_: $E(j)$\n",
    "  - _John or Mary is eating_ $E(j) \\vee E(m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - _Someone is eating_ $\\exists x: E(x)$ (__existential quantification__)\n",
    "  - _Everybody is eating_ $\\forall x: E(x)$ (__universal quantification__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - _Everybody is eating something_ $\\forall x \\exists y: E(x, y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some issues (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some phenomena seem easy to handle, but _only at first glance_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Red ball_: $R(x) \\wedge B(x)$\n",
    "\n",
    "This looks good: _Red balls_ are things that are both _red_ and _ball_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Large flea_: $L(x) \\wedge F(x)$\n",
    "\n",
    "This is problematic: what is $L$? How can you tell if something is _large_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some issues (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logical semantics has nearly __nothing to say about word meaning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bulk of research deals with the analyis of complex structures that are only rarely found in natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graph-based formalisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   - semantic representations are __networks of concepts__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   - dates back to the earliest days of computational linguistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   - hasn't penetrated everyday applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![ucca](ucca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hershcovich et al. 2019: [SemEval-2019 Task 1:\n",
    "Cross-lingual Semantic Parsing with UCCA](https://www.aclweb.org/anthology/S19-2001.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![amr](amr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "[AMR, Banarescu et al. 2013](https://aclanthology.org/W13-2322.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lexical relationships: synonymy, homonymy, hypernymy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Synonyms\n",
    "\n",
    "Pairs of words that mean roughly the same thing are called __synonyms__\n",
    "\n",
    "- _dog_ - _canine_\n",
    "- _buy_ - _purchase_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Q: are there \"perfect synonyms\", ever, in any language? Depends on our definition of meaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypernyms, hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A word is a __hypernym__ of another if it is a broader or more general concept of which the other is a special case, e.g. _mammal_ is the hypernym of _dog_, _rectangle_ is the hypernym of _square_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We also say that _dog_ is a __hyponym__ of _mammal_ and _square_ is a hyponym of _rectangle_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Q: in what way is this similar to the IS_A relationship in programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A lexical database available for [many languages](http://globalwordnet.org/resources/wordnets-in-the-world/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](wordnet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "<img src=\"wordnet2.jpg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## FrameNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Website: [https://framenet.icsi.berkeley.edu/](https://framenet.icsi.berkeley.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A resource based on __Frame Semantics__ (see e.g. [Fillmore & Baker 2001](https://s3.amazonaws.com/academia.edu.documents/38607839/framenet.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1502707461&Signature=7W66yd%2FSTG8r3BU1DK86lz1ar%2FQ%3D&response-content-disposition=inline%3B%20filename%3DFrame_Semantics_for_Text_Understanding.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "__Frames__ are script-like structures that represent a situation, event or object, and lists its typical participants or props, which are called __event roles__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Here's an example](https://framenet.icsi.berkeley.edu/fnReports/data/frameIndex.xml?frame=Apply_heat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLP can only imitate natural language understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The 'Mr. Hug' story (1976)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "http://www-formal.stanford.edu/jmc/mrhug.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### The story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\"A 61-year old furniture salesman was pushed down the shaft of a freight elevator yesterday in his downtown Brooklyn store by two robbers while a third attempted to crush him with the elevator car because they were dissatisfied with the $1,200 they had forced him to give them.\n",
    "The buffer springs at the bottom of the shaft prevented the car from crushing the salesman, John J. Hug, after he was pushed from the first floor to the basement. The car stopped about 12 inches above him as he flattened himself at the bottom of the pit. (...)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Questions\n",
    "\n",
    "- Who was in the store when the events began? Probably Mr. Hug alone.\n",
    "- (...)\n",
    "- Who had the money at the end? The robbers.\n",
    "- (...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### GPT3's answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![mrhug](mrhug.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ChatGPT's answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![chatgpt1](chatgpt1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ChatGPT's answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![chatgpt2](chatgpt2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A recent NYT story\n",
    "\n",
    "Hundreds of passengers were evacuated from the Port Authority Bus Terminal in Midtown Manhattan on Wednesday night when a suspicious bag was reported at Gate 75, the agency said. The Port Authority Police Department received the report about the bag at about 8:24 p.m., and the evacuation was ordered moments later. The bag was determined to pose no risk after 10 p.m., the Port Authority said. The New York City Fire Department said that it had received a call about a suspicious device just after 9 p.m. and that firefighters and emergency crews had stood by while police officers cleared the area. By 10:30 p.m., the Fire Department had left, and no injuries were reported, though the commutes of many passengers had been disrupted.\n",
    "\n",
    "[New York Times, 2023/11/15](https://www.nytimes.com/2023/11/15/nyregion/port-authority-manhattan-evacuation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Questions\n",
    "\n",
    "- Who was at the bus station when the events began?\n",
    "- What did the firefighters do?\n",
    "- Were any of the buses delayed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ChatGPT's answers\n",
    "\n",
    "![chatgpt3](chatgpt3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ChatGPT's answers\n",
    "\n",
    "![chatgpt4](chatgpt4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ChatGPT's answers\n",
    "\n",
    "![chatgpt5](chatgpt5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The octopus test (2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Highly recommended reading: [Bender & Koller 2020](https://aclanthology.org/2020.acl-main.463.pdf)\n",
    "\n",
    "Excerpt from the conclusion:\n",
    "\n",
    "_In this paper, we have argued that in contrast to some current hype, meaning cannot be learned from form alone. This means that even large language models such as BERT do not learn âmeaningâ; they learn some reflection of meaning into the linguistic form which is very useful in applications._ (Bender & Koller 2020, p. 5193) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
