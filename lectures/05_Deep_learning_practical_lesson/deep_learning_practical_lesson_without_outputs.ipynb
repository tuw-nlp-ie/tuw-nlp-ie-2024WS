{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUJ9cPl-Fry3"
   },
   "source": [
    "# Natural Language Processing and Information Extraction\n",
    "## Deep learning - practical session\n",
    "\n",
    "__Nov 22, 2024__\n",
    "\n",
    "__Varvara Arzt__\n",
    "\n",
    "The material of this lecture was created by __Ádám Kovács__ and extended by Varvara Arzt\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/tuw-nlp-ie/tuw-nlp-ie-2024WS/blob/main/lectures/05_Deep_learning_practical_lesson/deep_learning_practical_lesson_without_outputs.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-08G4DavFry5"
   },
   "source": [
    "During this lecture we are going to use a classification dataset from a shared task: [SemEval 2019 - Task 6](https://github.com/ZeyadZanaty/offenseval).\n",
    "\n",
    "SemEval (Semantic Evaluation) is a series of international NLP research workshops whose mission is to advance the current SOTA in semantic analysis. [Here](https://github.com/SemEval/SemEval2025/blob/main/tasks.md) you can find a list of shared tasks for SemEval-2025.\n",
    "\n",
    "The [SemEval 2019 - Task 6](https://github.com/ZeyadZanaty/offenseval) is about Identifying and Categorizing Offensive Language in Social Media.\n",
    "__Preparation:__\n",
    "- You will need the Semeval dataset (we will have code to download it)\n",
    "- You will need to install pytorch:\n",
    "    - pip install torch (for details on PyTorch installation depending on your OS, CUDA version etc. check the official [PyTorch documentation](https://pytorch.org/get-started/locally/))\n",
    "- You will also need to have pandas, torchtext, numpy and scikit learn installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_7oXPa0Fry6"
   },
   "source": [
    "We are going to use an open source library for building optimized deep learning models that can be run on GPUs, the library is called [Pytorch](https://pytorch.org/docs/stable/index.html). It is one of the most widely used libraries for building neural networks/deep learning models.\n",
    "\n",
    "In this lecture we are mostly using pure PyTorch models, but there are multiple libraries available to make it even easier to build neural networks. You are free to use them in your projects.\n",
    "Just to name a few:\n",
    "- TorchText: https://pytorch.org/text/stable/index.html\n",
    "- AllenNLP: https://github.com/allenai/allennlp\n",
    "- HuggingFace: https://huggingface.co\n",
    "\n",
    "__NOTE: It is advised to use Google Colab for this laboratory for free access to GPUs, and also for reproducibility.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZt9zm2LFry6",
    "outputId": "c2bdc279-bcad-45a5-fa44-d5c09b976c66"
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Y0mhic03d_a",
    "outputId": "344bf891-c924-4590-e55e-a7a086ed8f98"
   },
   "outputs": [],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4Xkf04_Fry7"
   },
   "outputs": [],
   "source": [
    "# Import the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeotTKMl3d_b"
   },
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDFv7TnVFry8"
   },
   "source": [
    "## Download the dataset and load it into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0gNCsikFry8",
    "outputId": "7f7c0a4a-559a-42dd-ded7-6e1d1cd517ee"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"./data\"):\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "u = urllib.request.URLopener()\n",
    "u.retrieve(\n",
    "    \"https://raw.githubusercontent.com/ZeyadZanaty/offenseval/master/datasets/training-v1/offenseval-training-v1.tsv\",\n",
    "    \"data/offenseval.tsv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xxkoCVUFry8"
   },
   "source": [
    "## Read in the dataset into a Pandas DataFrame\n",
    "Use `pd.read_csv` with the correct parameters to read in the dataset. If done correctly, `DataFrame` should have 5 columns,\n",
    "`id`, `tweet`, `subtask_a`, `subtask_b`, `subtask_c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14AzL6GHFry9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eef320fdacfdf485",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    train_data = pd.read_csv(\"./data/offenseval.tsv\", sep=\"\\t\")\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "rNCxGm0LFry-",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8f39b3b86623648c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c38ebe19-f5ba-42bb-a7c0-a8f0028def60"
   },
   "outputs": [],
   "source": [
    "train_data_unprocessed = read_dataset()\n",
    "train_data_unprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8sKz1zsFry-"
   },
   "source": [
    "## Convert `subtask_a` into a binary label\n",
    "The task is to classify the given tweets into two category: _offensive(OFF)_ , _not offensive (NOT)_. For machine learning algorithms you will need integer labels instead of strings. Add a new column to the dataframe called `label`, and transform the `subtask_a` column into a binary integer label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQ4VazgwFry-",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-595b437c85da4194",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform(train_data):\n",
    "    labels = {\"NOT\": 0, \"OFF\": 1}\n",
    "\n",
    "    train_data[\"label\"] = [labels[item] for item in train_data.subtask_a]\n",
    "    train_data[\"tweet\"] = train_data[\"tweet\"].str.replace(\"@USER\", \"\")\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSHYynQ3Fry_",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-56fa86b834804581",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = transform(train_data_unprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "t_9DrYdn3d_d",
    "outputId": "83805b34-45f1-495d-b528-3d5325a26c8e"
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNUUEApz3d_d",
    "outputId": "5e36ca26-0c39-4db8-8895-cd83effbe489"
   },
   "outputs": [],
   "source": [
    "train_data.groupby(\"subtask_a\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1vVLQwfFrzA"
   },
   "source": [
    "## Train a simple neural network on this dataset\n",
    "\n",
    "In this notebook we are going to build different neural architectures on the task:\n",
    "- A simple one layered feed forward neural network (FNN) with one-hot encoded vectors\n",
    "- Adding more layers to the FNN, making it a deep neural network\n",
    "- Instead of using one-hot encoded vectors we are going to add embedding vectors to the architecture, that takes the sequential nature of natural texts into account\n",
    "- Then we will train LSTM networks\n",
    "- At last, we will also build a Transformer architecture, that currently achieves SOTA results on a lot of tasks\n",
    "\n",
    "First we will build one-hot-encoded vectors for each sentence, and then use a simple feed forward neural network to predict the correct labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWIAidfzFrzA",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c242629b22cb523",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# First we need to import pytorch and set a fixed random seed number for reproducibility\n",
    "import torch\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypaOR-1EFrzA"
   },
   "source": [
    "### Split the dataset into a train and a validation dataset\n",
    "Use the random seed for splitting. You should split the dataset into 70% training data and 30% validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSeRGX4KFrzB",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20ba609174c640e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "\n",
    "def split_data(train_data, random_seed):\n",
    "    tr_data, val_data = split(train_data, test_size=0.3, random_state=SEED)\n",
    "    return tr_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bK6m0rRFrzB",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0e8a125310d3fea9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tr_data, val_data = split_data(train_data, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHxBtAYNFrzB"
   },
   "source": [
    "### Use CountVectorizer to prepare the features for the sentences\n",
    "_CountVectorizer_ is a great tool from _sklearn_ that helps us with basic preprocessing steps. It has lots of parameters to play with, you can check the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). It will:\n",
    "- Tokenize, lowercase the text\n",
    "- Filter out stopwords\n",
    "- Convert the text into one-hot encoded vectors\n",
    "- Select the _n_-best features\n",
    "\n",
    "We fit CountVectorizer using _3000_ features\n",
    "\n",
    "We will also _lemmatize_ texts using the _nltk_ package and its lemmatizer. Check the [docs](https://www.nltk.org/_modules/nltk/stem/wordnet.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6H3QFQQ3d_f",
    "outputId": "9ed17478-11a3-4f7b-cc24-7ec9bf02ac37"
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shzT5AX0FrzC",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0943811065a971f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "c8f11496-f926-4f27-d848-43b91cea471d"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")  # download tokenisation models\n",
    "nltk.download(\"wordnet\")  # download Wordnet dataset\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "\n",
    "def prepare_vectorizer(tr_data):\n",
    "    #max_features: build a vocabulary that only considers the top max_features ordered by term frequency across the corpus.\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=3000, tokenizer=LemmaTokenizer(), stop_words=\"english\"\n",
    "    )\n",
    "\n",
    "    word_to_ix = vectorizer.fit(tr_data.tweet)\n",
    "\n",
    "    return word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xq4NYTdcFrzC",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a2c6658aef3041dc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "word_to_ix = prepare_vectorizer(tr_data)\n",
    "# The vocab size is the length of the vocabulary, or the length of the feature vectors\n",
    "VOCAB_SIZE = len(word_to_ix.vocabulary_)\n",
    "assert VOCAB_SIZE == 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = word_to_ix.vocabulary_\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(word_to_ix.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(word_to_ix.get_stop_words())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE2Gn8JY3d_g"
   },
   "source": [
    "CountVectorizer can directly transform any sentence into a Bag-of-Words representation based on the corpus it is built on (Bag-of-Words representation of each document=accumulated one-hot vectors for all words in a document). It creates a document-term matrix with each row representing a document and each column addressing a token: CountVectorizer simply counts the number of times a token shows up in the document and uses this value as its weight\n",
    "\n",
    "![onehot](https://miro.medium.com/max/886/1*_da_YknoUuryRheNS-SYWQ.png)\n",
    "![bagofwords](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*3IACMnNpwVlCl8kSTJocPA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rlxFUWI3d_g",
    "outputId": "abe8cc9c-1898-4930-8a9b-e104b314dab2"
   },
   "outputs": [],
   "source": [
    "word_to_ix.transform([\"he loves science\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coKBNy7P3d_g",
    "outputId": "0d5dd483-99ee-40ac-9947-af1e79075453"
   },
   "outputs": [],
   "source": [
    "type(word_to_ix.transform([\"he loves science\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_positions = word_to_ix.transform([\"he loves doing research\"]).toarray().nonzero()\n",
    "non_zero_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = word_to_ix.vocabulary_\n",
    "reverse_vocab = {index: word for word, index in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_words = [reverse_vocab[idx] for idx in non_zero_positions[1]]  # [1] because Countvectorizer generates a document-term matrix where rows=docs & columns=terms\n",
    "non_zero_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4SD37O4FrzE",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d1819598c663eb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the correct device\n",
    "# It is important that every array should be on the same device or the training won't work\n",
    "# A device could be either the cpu or the gpu if it is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrlPM_d1FrzC"
   },
   "source": [
    "### Prepare the DataLoader for batch processing\n",
    "\n",
    "The __prepare_dataloader(..)__ function will take the training and the validation dataset and convert them to one-hot encoded vectors with the help of the initialized CountVectorizer.\n",
    "\n",
    "We prepare two FloatTensors and LongTensors for the converted tweets and labels of the training and the validation data.\n",
    "\n",
    "Then zip together the vectors with the labels as a list of tuples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-6VMlD-FrzD",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67b120b4ea6ba288",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the data loaders for the training and the validation sets\n",
    "# PyTorch operates on it's own datatype which is very similar to numpy's arrays\n",
    "# They are called Torch Tensors: https://pytorch.org/docs/stable/tensors.html\n",
    "# They are optimized for training neural networks\n",
    "def prepare_dataloader(tr_data, val_data, word_to_ix):\n",
    "    # First we transform the tweets into one-hot encoded vectors\n",
    "    # Then we create Torch Tensors from the list of the vectors\n",
    "    # It is also inportant to send the Tensors to the correct device\n",
    "    # All of the tensors should be on the same device when training\n",
    "    tr_data_vecs = torch.FloatTensor(word_to_ix.transform(tr_data.tweet).toarray()).to(\n",
    "        device\n",
    "    )\n",
    "    tr_labels = torch.LongTensor(tr_data.label.tolist()).to(device)\n",
    "\n",
    "    val_data_vecs = torch.FloatTensor(\n",
    "        word_to_ix.transform(val_data.tweet).toarray()\n",
    "    ).to(device)\n",
    "    val_labels = torch.LongTensor(val_data.label.tolist()).to(device)\n",
    "\n",
    "    tr_data_loader = [(sample, label) for sample, label in zip(tr_data_vecs, tr_labels)]\n",
    "    val_data_loader = [\n",
    "        (sample, label) for sample, label in zip(val_data_vecs, val_labels)\n",
    "    ]\n",
    "\n",
    "    return tr_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQG5rdlpFrzD",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-212fb18e207761c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tr_data_loader, val_data_loader = prepare_dataloader(tr_data, val_data, word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, usually you use `torch.utils.data.Dataset` data primitive to perform the operations reflected in `prepare_dataloader()` function: check out the [documentation for PyTorch's Datasets and DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxHwnckHFrzD"
   },
   "source": [
    "- __We have the correct lists now, it is time to initialize the DataLoader objects!__\n",
    "- __Create two DataLoader objects with the lists we have created__\n",
    "- __Shuffle the training data but not the validation data!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1DPygZyFrzE"
   },
   "outputs": [],
   "source": [
    "# We then define a BATCH_SIZE for our model\n",
    "# Usually we don't feed the whole dataset into our model at once\n",
    "# For this we have the BATCH_SIZE parameter\n",
    "# Try to experiment with different sized batches and see if changing this will improve the performance or not!\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BT3hbbGjFrzD",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96ac025a45bc4fec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# The DataLoader(https://pytorch.org/docs/stable/data.html) class helps us to prepare the training batches\n",
    "# It has a lot of useful parameters, one of it is _shuffle_ which will randomize the training dataset in each epoch\n",
    "# This can also improve the performance of our model\n",
    "def create_dataloader_iterators(tr_data_loader, val_data_loader, BATCH_SIZE):\n",
    "    train_iterator = DataLoader(\n",
    "        tr_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    valid_iterator = DataLoader(\n",
    "        val_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_iterator, valid_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zvvqcuk3FrzE",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7b88321ec3ee1096",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = create_dataloader_iterators(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    ")\n",
    "assert type(train_iterator) == torch.utils.data.dataloader.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uke6iYPh3d_i",
    "outputId": "970899de-7eba-4f52-c0b7-24d3ae533df7"
   },
   "outputs": [],
   "source": [
    "valid_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WUTDwv2FrzE"
   },
   "source": [
    "### Building the first PyTorch model\n",
    "At first, the model will contain a single Linear layer that takes one-hot-encoded vectors and trainsforms it into the dimension of the __NUM_LABELS__ (how many classes we are trying to predict). Then, run through the output on a softmax activation to produce probabilites of the classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqwUwPUdFrzF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00fb572132edf99a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Note that we could add more Linear Layers here connected to each other\n",
    "        # Then we would also need to have a HIDDEN_SIZE hyperparameter as an input to our model\n",
    "        # Then, with activation functions between them (e.g. RELU) we could have a \"Deep\" model\n",
    "        # This is just an example for a shallow network\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "    def forward(self, bow_vec, sequence_lens):\n",
    "        # Ignore sequence_lens for now!\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        # Softmax will provide a probability distribution among the classes\n",
    "        # We can then use this for our loss function\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lr-4sjO3FrzF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3cbec9b993598632",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The INPUT_DIM is the size of our input vectors\n",
    "INPUT_DIM = VOCAB_SIZE\n",
    "# We have only 2 classes\n",
    "OUTPUT_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVxRlyR-FrzF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-203697b21306ccb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "# At first it is untrained, the weights are assigned random\n",
    "model = BoWClassifier(OUTPUT_DIM, INPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEIXHRUTFrzF"
   },
   "outputs": [],
   "source": [
    "# Set the optimizer and the loss function!\n",
    "# https://pytorch.org/docs/stable/optim.html\n",
    "import torch.optim as optim\n",
    "\n",
    "# The optimizer will update the weights of our model based on the loss function\n",
    "# This is essential for correct training\n",
    "# The _lr_ parameter is the learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0pDsTdKFrzG",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9852177c09074615",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Copy the model and the loss function to the correct device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BSC-ttlFrzG",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-50c925cbe0576fd3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert model.linear.out_features == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCrTcch_FrzG"
   },
   "source": [
    "### Training and evaluating PyTorch models\n",
    "- __calculate_performance__: This should calculate the batch-wise precision, recall, and fscore of your model!\n",
    "- __train__ - Train your model on the training data! This function should set the model to training mode, then use the given iterator to iterate through the training samples and make predictions using the provided model. You should then propagate back the error with the loss function and the optimizer. Finally return the average epoch loss and performance!\n",
    "- __evaluate__ - Evaluate your model on the validation dataset. This function is essentially the same as the trainnig function, but you should set your model to eval mode and don't propagate back the errors to your weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TWQekCdFrzG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1818f7b4bce37196",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def calculate_performance(preds, y):\n",
    "    \"\"\"\n",
    "    Returns precision, recall, fscore per batch\n",
    "    \"\"\"\n",
    "    # Get the predicted label from the probabilities\n",
    "    rounded_preds = preds.argmax(1)\n",
    "\n",
    "    # Calculate the correct predictions batch-wise and calculate precision, recall, and fscore\n",
    "    # WARNING: Tensors here could be on the GPU, so make sure to copy everything to CPU\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "        rounded_preds.cpu(), y.cpu()\n",
    "    )\n",
    "\n",
    "    return precision[1], recall[1], fscore[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhzACM5IFrzG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea8beb3df906f9a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    # We will calculate loss and accuracy epoch-wise based on average batch accuracy\n",
    "    epoch_loss = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_fscore = 0\n",
    "\n",
    "    # You always need to set your model to training mode\n",
    "    # If you don't set your model to training mode the error won't propagate back to the weights\n",
    "    model.train()\n",
    "\n",
    "    # We calculate the error on batches so the iterator will return matrices with shape [BATCH_SIZE, VOCAB_SIZE]\n",
    "    for batch in iterator:\n",
    "        text_vecs = batch[0]\n",
    "        labels = batch[1]\n",
    "        sen_lens = []\n",
    "        texts = []\n",
    "\n",
    "        # This is for later!\n",
    "        if len(batch) > 2:\n",
    "            sen_lens = batch[2]\n",
    "            texts = batch[3]\n",
    "\n",
    "        # We reset the gradients from the last step, so the loss will be calculated correctly (and not added together)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # This runs the forward function on your model (you don't need to call it directly)\n",
    "        predictions = model(text_vecs, sen_lens)\n",
    "\n",
    "        # Calculate the loss and the accuracy on the predictions (the predictions are log probabilities, remember!)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        prec, recall, fscore = calculate_performance(predictions, labels)\n",
    "\n",
    "        # Propagate the error back on the model (this means adjusting the initial weights in your model)\n",
    "        # Calculate gradients on parameters that requries grad\n",
    "        loss.backward()\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # We add batch-wise loss to the epoch-wise loss\n",
    "        epoch_loss += loss.item()\n",
    "        # We also do the same with the scores\n",
    "        epoch_prec += prec.item()\n",
    "        epoch_recall += recall.item()\n",
    "        epoch_fscore += fscore.item()\n",
    "    return (\n",
    "        epoch_loss / len(iterator),\n",
    "        epoch_prec / len(iterator),\n",
    "        epoch_recall / len(iterator),\n",
    "        epoch_fscore / len(iterator),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASFglaVtFrzH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-810fadb1db8e2028",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The evaluation is done on the validation dataset\n",
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_fscore = 0\n",
    "    # On the validation dataset we don't want training so we need to set the model on evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Also tell Pytorch to not propagate any error backwards in the model or calculate gradients\n",
    "    # This is needed when you only want to make predictions and use your model in inference mode!\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # The remaining part is the same with the difference of not using the optimizer to backpropagation\n",
    "        for batch in iterator:\n",
    "            text_vecs = batch[0]\n",
    "            labels = batch[1]\n",
    "            sen_lens = []\n",
    "            texts = []\n",
    "\n",
    "            if len(batch) > 2:\n",
    "                sen_lens = batch[2]\n",
    "                texts = batch[3]\n",
    "\n",
    "            predictions = model(text_vecs, sen_lens)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            prec, recall, fscore = calculate_performance(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_prec += prec.item()\n",
    "            epoch_recall += recall.item()\n",
    "            epoch_fscore += fscore.item()\n",
    "\n",
    "    # Return averaged loss on the whole epoch!\n",
    "    return (\n",
    "        epoch_loss / len(iterator),\n",
    "        epoch_prec / len(iterator),\n",
    "        epoch_recall / len(iterator),\n",
    "        epoch_fscore / len(iterator),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzRshE3-FrzH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73c8635f8fc4a7fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# This is just for measuring training time!\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, valid_losses, n_epochs):\n",
    "    \"\"\"\n",
    "    Function to plot training and validation losses.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, n_epochs + 1), train_losses, label=\"Training Loss\")\n",
    "    plt.plot(range(1, n_epochs + 1), valid_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBcx1vxBFrzH"
   },
   "source": [
    "### Training loop!\n",
    "Below is the training loop of our model! Try to set an EPOCH number that will correctly train your model :) (it is not underfitted but neither overfitted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGaJR3xTFrzH"
   },
   "outputs": [],
   "source": [
    "def training_loop(epoch_number=15):\n",
    "    # Set an EPOCH number!\n",
    "    N_EPOCHS = epoch_number\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "\n",
    "    # Lists to store loss values for plotting\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # We loop forward on the epoch number\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model on the training set using the dataloader\n",
    "        train_loss, train_prec, train_rec, train_fscore = train(\n",
    "            model, train_iterator, optimizer, criterion\n",
    "        )\n",
    "        # And validate your model on the validation set\n",
    "        valid_loss, valid_prec, valid_rec, valid_fscore = evaluate(\n",
    "            model, valid_iterator, criterion\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # If we find a better model, we save the weights so later we may want to reload it\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(\n",
    "            f\"\\tTrain Loss: {train_loss:.3f} | Train Prec: {train_prec*100:.2f}% | Train Rec: {train_rec*100:.2f}% | Train Fscore: {train_fscore*100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"\\t Val. Loss: {valid_loss:.3f} |  Val Prec: {valid_prec*100:.2f}% | Val Rec: {valid_rec*100:.2f}% | Val Fscore: {valid_fscore*100:.2f}%\"\n",
    "        )\n",
    "    plot_losses(train_losses, valid_losses, N_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIm70jWgQq21",
    "outputId": "caeb182a-667f-49be-afa7-78ba6fe6027d"
   },
   "outputs": [],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4B_wdUgFrzI"
   },
   "source": [
    "\n",
    "__NOTE: DON'T FORGET TO RERUN THE MODEL INITIALIZATION WHEN YOU ARE TRYING TO RUN THE MODEL MULTIPLE TIMES. IF YOU DON'T REINITIALIZE THE MODEL IT WILL CONTINUE THE TRAINING WHERE IT HAS STOPPED LAST TIME AND DOESN'T RUN FROM SRATCH!__\n",
    "\n",
    "These lines:\n",
    "\n",
    "```python\n",
    "model = BoWClassifier(OUTPUT_DIM, INPUT_DIM)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.NLLLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "```\n",
    "\n",
    "This will reinitialize the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOpuzSyfPwBh"
   },
   "outputs": [],
   "source": [
    "def reinitialize(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.NLLLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgflJA47P3O-"
   },
   "outputs": [],
   "source": [
    "reinitialize(BoWClassifier(OUTPUT_DIM, INPUT_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFcqasArFrzI"
   },
   "source": [
    "## Add more linear layers to the model and experiment with other hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSv9C_heFrzJ"
   },
   "source": [
    "### More layers\n",
    "\n",
    "Currently we only have a single linear layers in our model. We are now adding more linear layers to the model.\n",
    "We also introduce a HIDDEN_SIZE parameter that will be the size of the intermediate representation between the linear layers. Also adding a RELU activation function between the linear layers.\n",
    "\n",
    "See more:\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "- https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S4Ytz8HFrzJ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f71eea2d6e70ad97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class BoWDeepClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size, hidden_size):\n",
    "        super(BoWDeepClassifier, self).__init__()\n",
    "        # First linear layer\n",
    "        self.linear1 = nn.Linear(vocab_size, hidden_size)\n",
    "        # Non-linear activation function between them\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        # Second layer\n",
    "        self.linear2 = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, bow_vec, sequence_lens):\n",
    "        # Run the input vector through every layer\n",
    "        output = self.linear1(bow_vec)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear2(output)\n",
    "\n",
    "        # Get the probabilities\n",
    "        return F.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5tw97UGFrzK"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 200\n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7flTZ3vgFrzK"
   },
   "outputs": [],
   "source": [
    "model = BoWDeepClassifier(OUTPUT_DIM, INPUT_DIM, HIDDEN_SIZE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNZV21ShFrzK",
    "outputId": "9fac20f9-bbb4-4ad4-97bd-3f8c52bee3b8"
   },
   "outputs": [],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRInQ1ToFrzK"
   },
   "source": [
    "## Implement automatic early-stopping in the training loop\n",
    "Early stopping is a very easy method to avoid the overfitting of your model.\n",
    "\n",
    "We could:\n",
    "- Save the training and the validation loss of the last two epochs (if you are at least in the third epoch)\n",
    "- If the loss increased in the last two epoch on the training data but descreased or stagnated in the validation data, you should stop the training automatically!\n",
    "\n",
    "In the training loop below we do a very basic early stopping after there is no improvement in validation loss on a predefined number of consecutive epochs (=patience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pblBEo87FrzL",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d460cc4aa3dd437",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reinitialize(BoWClassifier(OUTPUT_DIM, INPUT_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyxNctC13d_m"
   },
   "outputs": [],
   "source": [
    "model = BoWDeepClassifier(OUTPUT_DIM, INPUT_DIM, HIDDEN_SIZE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Bl4-i-c3d_m"
   },
   "outputs": [],
   "source": [
    "def training_loop(epoch_number=15, patience=3):\n",
    "    # Set an EPOCH number!\n",
    "    N_EPOCHS = epoch_number\n",
    "    consecutive_no_improvement = 0\n",
    "\n",
    "    best_valid_loss = float(\"inf\")  # ensures the 1st validation loss will always be considered better\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # We loop forward on the epoch number\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model on the training set using the dataloader\n",
    "        train_loss, train_prec, train_rec, train_fscore = train(\n",
    "            model, train_iterator, optimizer, criterion\n",
    "        )\n",
    "        # And validate your model on the validation set\n",
    "        valid_loss, valid_prec, valid_rec, valid_fscore = evaluate(\n",
    "            model, valid_iterator, criterion\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # If we find a better model, we save the weights so later we may want to reload it\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            consecutive_no_improvement = 0\n",
    "            torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "\n",
    "        else:\n",
    "            consecutive_no_improvement += 1\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(\n",
    "            f\"\\tTrain Loss: {train_loss:.3f} | Train Prec: {train_prec*100:.2f}% | Train Rec: {train_rec*100:.2f}% | Train Fscore: {train_fscore*100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"\\t Val. Loss: {valid_loss:.3f} |  Val Prec: {valid_prec*100:.2f}% | Val Rec: {valid_rec*100:.2f}% | Val Fscore: {valid_fscore*100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Check for early stopping\n",
    "        if consecutive_no_improvement >= patience:\n",
    "            print(f\"No improvement in validation loss for {patience} consecutive epochs. Early stopping after epoch {epoch+1}.\")\n",
    "            break  # Terminate training loop\n",
    "\n",
    "    plot_losses(train_losses, valid_losses, n_epochs=epoch+1)\n",
    "        \n",
    "    return best_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DH9SEm3c3d_m",
    "outputId": "551a0d27-c3f2-45c9-f970-fc96b60cb428"
   },
   "outputs": [],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAN4Y5s3FrzL"
   },
   "source": [
    "## Handling class imbalance\n",
    "Our data is imbalanced, the first class has twice the population of the second class.\n",
    "\n",
    "One way of handling imbalanced data is to weight the loss function, so it penalizes errors on the smaller class.\n",
    "\n",
    "Look at the documentation of the loss function: https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n",
    "\n",
    "Set the weights based on the inverse population of the classes, so a class with fewer samples is penalized more heavily for errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9_wXYqlFrzL",
    "outputId": "4617dc32-3f17-49d0-b8ae-5320e01022d8"
   },
   "outputs": [],
   "source": [
    "tr_data.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FoqDTQIFrzL",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6ebf131781a3332d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.Tensor([1, 2])  # errors for class 1 will be penalised twice as heavily as errors for class 0\n",
    "criterion = nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBu230DWRYwK"
   },
   "source": [
    "## Adding an Embedding Layer to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F_lJrzr3d_m"
   },
   "source": [
    "- We only used Bag-of-Words representations as our features until now\n",
    "- Now we will introduce an [embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) layer into our network.\n",
    "- We will feed the words into our network one-by-one, and the layer will learn a dense vector representation for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI0KsOfr3d_n"
   },
   "source": [
    "![embeddingbag](https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png)\n",
    "\n",
    "_from pytorch.org_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5uYW1OmUpfJ"
   },
   "outputs": [],
   "source": [
    "# Get the CountVectorizer's analyzer method to get the word-id mapping\n",
    "an = word_to_ix.build_analyzer()  # handles preprocessing, tokenisation and removal of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Syg7NPVxUsWZ",
    "outputId": "ce371a2f-fa78-4c6e-ba9b-a1837341f898"
   },
   "outputs": [],
   "source": [
    "an(\"hello my name is varya\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9JTmf6R3d_n"
   },
   "source": [
    "Get the key with maximum values in a dictionary (keys are tokens; values are number of occurrences):\n",
    "\n",
    "`word_to_ix.vocabulary_` returns mapping of terms (tokens) to feature indices (number of occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jRJ_cbeeUvMy",
    "outputId": "b32dfc67-af54-4330-e066-158a16738f1f"
   },
   "outputs": [],
   "source": [
    "max(word_to_ix.vocabulary_, key=word_to_ix.vocabulary_.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpHfQzTp3d_n"
   },
   "source": [
    "As we remember, we passed a parameter `max_features=3000` to a CountVectorizer, so our vocabulary size is 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG9xZYBQ7VNQ",
    "outputId": "57e737a3-616f-4b44-f091-4cb07cbd7312"
   },
   "outputs": [],
   "source": [
    "len(word_to_ix.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbU3fq40UxyR"
   },
   "outputs": [],
   "source": [
    "def create_input(dataset, analyzer, vocabulary):\n",
    "    dataset_as_indices = []\n",
    "\n",
    "    # We go through each tweet in the dataset\n",
    "    # We need to add two additional symbols to the vocabulary\n",
    "    # We have 3000 features, ranged 0-2999\n",
    "    # We add 3000 as an id for the \"unknown\" words not among the features\n",
    "    # 3001 will be the symbol for padding, but about this later!\n",
    "    for tweet in dataset:\n",
    "        tokens = analyzer(tweet)\n",
    "        token_ids = []\n",
    "\n",
    "        for token in tokens:\n",
    "            # if the token is in the vocab, we add the id\n",
    "            if token in vocabulary:\n",
    "                token_ids.append(vocabulary[token])\n",
    "            # else we add the id of the unknown token\n",
    "            else:\n",
    "                token_ids.append(3000)\n",
    "\n",
    "        # if we removed every token during preprocessing (stopword removal, lemmatization), we add the unknown token to the list so it won't be empty\n",
    "        if not token_ids:\n",
    "            token_ids.append(3000)\n",
    "        dataset_as_indices.append(torch.LongTensor(token_ids).to(device))\n",
    "\n",
    "    return dataset_as_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qxWFBdj3d_n",
    "outputId": "b2ce0d82-e7ad-44ff-bfa7-03e67cb28bbe"
   },
   "outputs": [],
   "source": [
    "tr_data.tweet.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTJ3kNpf3d_n",
    "outputId": "c39c0b26-c737-49d3-f692-e3ffdedd807c"
   },
   "outputs": [],
   "source": [
    "len(tr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSt_fM4f3d_o",
    "outputId": "385a7dfe-ba94-40e2-fde5-73920075bd45"
   },
   "outputs": [],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDZmvZmwU3oI"
   },
   "outputs": [],
   "source": [
    "# We add the length of the tweets so sentences with similar lengths will be next to each other\n",
    "# This can be important because of padding\n",
    "tr_data[\"length\"] = tr_data.tweet.str.len()\n",
    "val_data[\"length\"] = val_data.tweet.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3SypHXUVAOR",
    "outputId": "4d929860-7785-45b2-a940-6128b24e9e78"
   },
   "outputs": [],
   "source": [
    "tr_data.tweet.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJyVrIpLVHjA"
   },
   "outputs": [],
   "source": [
    "tr_data = tr_data.sort_values(by=\"length\")\n",
    "val_data = val_data.sort_values(by=\"length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLxMeEF6VJto"
   },
   "outputs": [],
   "source": [
    "# We create the dataset as ids of tokens\n",
    "dataset_as_ids = create_input(tr_data.tweet, an, word_to_ix.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFAxmX983d_o"
   },
   "source": [
    "Actually, when experimenting with different indices, you will see that many tensors that give a numeric representation of each tweet contain only one element. This is because of removal of stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXRm0Qc0VMRo",
    "outputId": "eab48cae-1b22-4364-b411-8f9e1d65178e"
   },
   "outputs": [],
   "source": [
    "dataset_as_ids[140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTthCdOK3d_o"
   },
   "source": [
    "Many of them contain only unknown token with an index `3000` (so, it was really important to add it, otherwise our tensor would be empty):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqMlyXM73d_o",
    "outputId": "3e0c6a89-7a20-4674-a9b1-40be012f2bf0"
   },
   "outputs": [],
   "source": [
    "dataset_as_ids[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsRwAz8V3d_o"
   },
   "source": [
    "### Padding\n",
    "\n",
    "- We didn't need to take care of input padding when using Bag-of-Words vectors\n",
    "- Padding handles different sized inputs\n",
    "- We can pad sequences from the left, or from the right\n",
    "\n",
    "![padding](https://miro.medium.com/max/1218/1*zsIXWoN0_CE9PXzmY3tIjQ.png)\n",
    "\n",
    "_image from https://towardsdatascience.com/nlp-preparing-text-for-deep-learning-model-using-tensorflow2-461428138657_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4cYXPNg3d_o"
   },
   "source": [
    "`torch.nn.utils.rnn.pad_sequence` takes a list of tensors as input (sequences), calculates max length, and then pads all the sequences with `padding_value` to make them all have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlFl5MTtVb8J",
    "outputId": "2770b512-b981-479c-e5b4-e191fefc8bfa"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# pad_sequence will take care of the padding\n",
    "# we will need to provide a padding_value to it\n",
    "padded = pad_sequence(dataset_as_ids, batch_first=True, padding_value=3001)\n",
    "padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me6QHFBV3d_p"
   },
   "source": [
    "Here you can see the dimension of `padded`, so max length among the sequences is 62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oYS45bb3d_p",
    "outputId": "617c46da-aadc-4ead-febc-bec69859b159"
   },
   "outputs": [],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCPFCrMbXIAs"
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader_with_padding(tr_data, val_data, word_to_ix):\n",
    "    # First create the id representations of the input vectors\n",
    "    # Then pad the sequences so all of the input is the same size\n",
    "    # We padded texts for the whole dataset, this could have been done batch-wise also!\n",
    "    tr_data_vecs = pad_sequence(\n",
    "        create_input(tr_data.tweet, an, word_to_ix.vocabulary_),\n",
    "        batch_first=True,\n",
    "        padding_value=3001,\n",
    "    )\n",
    "    tr_labels = torch.LongTensor(tr_data.label.tolist()).to(device)\n",
    "    tr_lens = torch.LongTensor(\n",
    "        [len(i) for i in create_input(tr_data.tweet, an, word_to_ix.vocabulary_)] #len of tweets\n",
    "    )\n",
    "    print(f\"Original Training sequence lengths before Padding: {tr_lens}\")\n",
    "    print(f\"Training sequence lengths tensor shape: {tr_lens.shape}\")\n",
    "\n",
    "    # We also add the texts to the batches\n",
    "    # This is for the Transformer models, you wont need this in the next experiments\n",
    "    tr_sents = tr_data.tweet.tolist()\n",
    "\n",
    "    val_data_vecs = pad_sequence(\n",
    "        create_input(val_data.tweet, an, word_to_ix.vocabulary_),\n",
    "        batch_first=True,\n",
    "        padding_value=3001,\n",
    "    )\n",
    "    val_labels = torch.LongTensor(val_data.label.tolist()).to(device)\n",
    "    val_lens = torch.LongTensor(\n",
    "        [len(i) for i in create_input(val_data.tweet, an, word_to_ix.vocabulary_)]\n",
    "    )\n",
    "\n",
    "    val_sents = val_data.tweet.tolist()\n",
    "\n",
    "    tr_data_loader = [\n",
    "        (sample, label, length, sent)\n",
    "        for sample, label, length, sent in zip(\n",
    "            tr_data_vecs, tr_labels, tr_lens, tr_sents\n",
    "        )\n",
    "    ]\n",
    "    val_data_loader = [\n",
    "        (sample, label, length, sent)\n",
    "        for sample, label, length, sent in zip(\n",
    "            val_data_vecs, val_labels, val_lens, val_sents\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return tr_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZvbpqCwXY3E",
    "outputId": "c097e26f-f49f-4269-8efc-cfb707d4cd22"
   },
   "outputs": [],
   "source": [
    "tr_data_loader, val_data_loader = prepare_dataloader_with_padding(\n",
    "    tr_data, val_data, word_to_ix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBSJgL9rXgDG"
   },
   "outputs": [],
   "source": [
    "def create_dataloader_iterators_with_padding(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    "):\n",
    "    train_iterator = DataLoader(\n",
    "        tr_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    valid_iterator = DataLoader(\n",
    "        val_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_iterator, valid_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XLM8WHqZCim"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = create_dataloader_iterators_with_padding(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdxivR4r3d_p"
   },
   "source": [
    "`next(iter(train_iterator))` returns a single batch of data (=batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrBaXBnaWk9t",
    "outputId": "a8fa419b-9ae2-4f2e-cbfe-f2bacd27090c"
   },
   "outputs": [],
   "source": [
    "next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLbPdOtA3d_q",
    "outputId": "77069a65-801a-4fc0-fdc3-7bdb7561571c"
   },
   "outputs": [],
   "source": [
    "samples, labels, lengths, sents = next(iter(train_iterator))\n",
    "print(f'Dimension of a tensor with data samples on each iteration (2D tensor of shape (BATCH_SIZE, max_sequence_length)): {samples.shape}')\n",
    "print(f'Number of tweets in the batch: {len(sents)}')\n",
    "print(samples[1]) # 2nd sample with X unique ids that are then padded to tensor len=62\n",
    "print(lengths[1]) # original length of the 2nd sample (before padding)\n",
    "print(sents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8XktMyY3d_q"
   },
   "source": [
    "![embedding](https://github.com/bentrevett/pytorch-sentiment-analysis/raw/b4efbefa47672174394a8b6a27d4e7bc193bc224/assets/sentiment8.png)\n",
    "\n",
    "_Image from bentrevett_: (BoW) model with an embedding layer and a pooling operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Pooling:\n",
    "\n",
    "`[[0.1, 0.3, 0.2],`  # \"I\"\n",
    "\n",
    " `[0.5, 0.7, 0.6],`  # \"hate\"\n",
    "\n",
    " `[0.2, 0.1, 0.3],`  # \"this\"\n",
    " \n",
    " `[0.4, 0.9, 0.8]]`  # \"film\"\n",
    "\n",
    "Max pooling (along the sequence dimension): `[0.5, 0.9, 0.8]` represents the whole tweet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k85Rbx-3ZLq9"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BoWClassifierWithEmbedding(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size, embedding_dim):\n",
    "        super(BoWClassifierWithEmbedding, self).__init__()\n",
    "\n",
    "        # We define the embedding layer here\n",
    "        # It will convert a list of ids: [1, 50, 64, 2006]\n",
    "        # Into a list of vectors, one for each word\n",
    "        # The embedding layer will learn the vectors from the contexts\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=3001)\n",
    "        # We could also load precomputed embeddings, e.g. GloVe, in some cases we don't want to train the embedding layer\n",
    "        # In this case we enable the training\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "        self.linear = nn.Linear(embedding_dim, num_labels)\n",
    "\n",
    "    def forward(self, text, sequence_lens):\n",
    "        # First we create the embedded vectors\n",
    "        embedded = self.embedding(text)  # dim=64x62x100 (batch_size x seq_len x embedding_dim)\n",
    "        #print(embedded.shape)\n",
    "        #print(embedded.shape[1])\n",
    "        # We need a pooling to convert a list of embedded words to a sentence vector\n",
    "        # We could have chosen different pooling, e.g. min, max, average..\n",
    "        # With LSTM we also do a pooling, just smarter\n",
    "        pooled = F.max_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1)  # dim=64x100 (batch_size x embedding_dim)\n",
    "        #print(pooled.shape)\n",
    "        return F.log_softmax(self.linear(pooled), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwBofSXr3d_q"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = VOCAB_SIZE + 2  # 3002\n",
    "OUTPUT_DIM = 2\n",
    "EMBEDDING_DIM = 100  # embedding layer will have an embedding vector for each of the 3000 vocabulary words, plus vectors for <UNK> and <PAD>\n",
    "HIDDEN_DIM = 20\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = BoWClassifierWithEmbedding(OUTPUT_DIM, INPUT_DIM, EMBEDDING_DIM)\n",
    "#model = LSTMClassifier(OUTPUT_DIM, INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9H7nwaH3d_q"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taiga3wN3d_q",
    "outputId": "c6c3bd65-9dc3-4fda-f795-709653bfc642"
   },
   "outputs": [],
   "source": [
    "training_loop(epoch_number=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KC-dHUk3d_q"
   },
   "source": [
    "## Standard RNNs & LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4c7dR4C3d_q"
   },
   "source": [
    "Unrolled RNN (image source: [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)):\n",
    "\n",
    "![unrolled_rnn1](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Gje5sbL3d_q"
   },
   "source": [
    "Repeating module in the standard RNN (image source: [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)):\n",
    "\n",
    "![rnn_module](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppm_CVtY3d_q"
   },
   "source": [
    "Repeating module in the LSTM (image source: [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))\n",
    "\n",
    "![repeating_module_lstm](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4-IuFuR3d_q"
   },
   "source": [
    "Output of the LSTM layer..\n",
    "\n",
    "![lstm](https://i.stack.imgur.com/SjnTl.png)\n",
    "\n",
    "_image from stackoverflow_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGOrrC2U3d_q"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=3001)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        # Documentation: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            batch_first=True,\n",
    "            num_layers=1,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_dim, num_labels)\n",
    "        # Dropout to overcome overfitting\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, text, sequence_lens):\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        # To ensure LSTM doesn't learn gradients for the id of the padding symbol\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, sequence_lens, enforce_sorted=False, batch_first=True\n",
    "        )\n",
    "        packed_outputs, (h, c) = self.lstm(packed)\n",
    "        # extract LSTM outputs (not used here)\n",
    "        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_outputs, batch_first=True\n",
    "        )\n",
    "\n",
    "        # We use the last hidden vector from LSTM\n",
    "        y = self.linear(h[-1])\n",
    "        log_probs = F.log_softmax(y, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QgKkr4bZSPG"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = VOCAB_SIZE + 2\n",
    "OUTPUT_DIM = 2\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 20\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#model = BoWClassifierWithEmbedding(OUTPUT_DIM, INPUT_DIM, EMBEDDING_DIM)\n",
    "model = LSTMClassifier(OUTPUT_DIM, INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVrF6CgmZUeg"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHCHriijZU9F",
    "outputId": "7709e9e3-9426-4f11-b620-2b5ff8c06c97"
   },
   "outputs": [],
   "source": [
    "training_loop(epoch_number=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interested in LSTMs? Check out the recent paper by the group of Sepp Hochreiter [xLSTM: Extended Long Short-Term Memory](https://arxiv.org/abs/2405.04517)\n",
    "- Exponential Gating\n",
    "- New memory structure to address long-term dependencies problem of RNNs and initial LSTMs\n",
    "- mLSTM: address the problem of lacking parallelisation in LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6HJydBI3d_r"
   },
   "source": [
    "#### CNN for NLP\n",
    "\n",
    "- works with input of fixed length (to handle it we need padding: fill sequences of different length with tokens that do not contain any meaning)\n",
    "- kernels (filters) in the visualisation below correspond to kernels for bigrams, trigrams and and tetragrams (2 for each type of kernels)\n",
    "- In Computer Vision, our filters slide over local patches of an image, but in NLP we typically use filters that slide over full rows of the matrix (words). Thus, the second dimension of our filters is usually the same as the number of columns of the input matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSi04xtI3d_r"
   },
   "source": [
    "CNN architecture for NLP introduced in [Zhang et al. A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification. 2015](https://arxiv.org/pdf/1510.03820.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLx6p6f2Y69C"
   },
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCLmfXf03d_r"
   },
   "source": [
    "## Attention mechanism in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKbKwWUV3d_r"
   },
   "source": [
    "To recap: seq2seq: encoder-decoder architecture with 2 RNNs without an attention block (image source: [medium article](https://towardsdatascience.com/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346))\n",
    "\n",
    "![encoder_decoder_rnn](https://miro.medium.com/v2/resize:fit:720/format:webp/1*1JcHGUU7rFgtXC_mydUA_Q.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Attention mechanism and neural machine translation\n",
    "\n",
    "Machine translation\n",
    "\n",
    "fascinating history that started more than 100 years ago (translating machine of Troyanskii, Georgetown–IBM experiment, ...): some of these experiments were driven by the Cold War\n",
    "\n",
    "- rule-based systems\n",
    "- statistical machine translation (phrase-based statistical machine translation is SOTA until 2016)\n",
    "- NN based approaches without attention mechanism\n",
    "- RNN based Encoder-Decoder architecture with attention mechanism (introduced in 2014 in the paper [Bengio et al. Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)): read [this Google Blog](https://blog.research.google/2016/09/a-neural-network-for-machine.html) from 2016 on machine translation system they introduced back then, namely Google Neural Machine Translation (GNMT) that contained 8 RNN layers in the encoder and decoder + attention mechanism\n",
    "- Attention is all you need :D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiQKQ9ub3d_r"
   },
   "source": [
    "![attention_encoder_decoder](https://miro.medium.com/v2/resize:fit:640/format:webp/1*KrCUK30Y1R7TV7xE-ltcpg.png)\n",
    "\n",
    "Image source: [medium article](https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT0P2gIA3d_r"
   },
   "source": [
    "### Problems with recurrent neural networks:\n",
    "\n",
    "Recall that we used recurrent neural cells, specifically LSTMs to encode a list of vectors into a sentence vector.\n",
    "\n",
    "- Problem 1. No parallelism\n",
    "\n",
    "        - LSTMs are recurrent, they rely on their left and right history, so the symbols need to be processed in order -> no parallelism.\n",
    "\n",
    "- Problem 2. Long-range dependencies\n",
    "\n",
    "        - Long-range dependencies are not infrequent in NLP.\n",
    "\n",
    "        - \"The people/person who called and wanted to rent your house when you go away next year are/is from California\" -- Miller & Chomsky 1963\n",
    "\n",
    "        - LSTMs have a problem capturing these because there are too many backpropagation steps between the symbols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx-3mF6O3d_s"
   },
   "source": [
    "## Transformers\n",
    "\n",
    "Good explanation of transformer architecture: https://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "![transformer_architecture](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)\n",
    "\n",
    "Image source: https://machinelearningmastery.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Attention is all you need: no convolutions or recurrences are used. Introduction of multi-headed self-attention. \n",
    "\n",
    "\"The animal didn't cross the street because it was too tired\" -- We want self-attention to associate *it* with *animal*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self_attention](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*maneqIvralwRZWf0g3hS5w.png)\n",
    "\n",
    "Image source: [towardsdatascience](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021#4c16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![self_attention_detailed](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*Rv_pntt-N2WL7LMbIptHxQ.png)\n",
    "\n",
    "Image source: [towardsdatascience](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021#4c16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhkOwAbq3d_s"
   },
   "source": [
    "Introduced in [Attention Is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) by Vaswani et al., 2017\n",
    "\n",
    "Transformers solve Problem 1 by relying purely on attention instead of recurrence.\n",
    "\n",
    "Not having recurrent connections means that sequence position no longer matters.\n",
    "\n",
    "Recurrence is replaced by self-attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUqe0zbX3d_s"
   },
   "source": [
    "- Transformers are available in the __transformers__ Python package: https://github.com/huggingface/transformers.\n",
    "- There are thousands of pretrained transformers models in different languages and with different architectures.\n",
    "- With the huggingface package there is a unified interface to download and use all the models. Browse https://huggingface.co/models for more!\n",
    "- There is also a great blog post to understand the architecture of transformers: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GTFkorG3d_s"
   },
   "source": [
    "### BERT\n",
    "\n",
    "[BERT](https://www.aclweb.org/anthology/N19-1423/): Pre-training of Deep Bidirectional Transformers for Language Understanding by Devlin et al. 2018\n",
    "\n",
    "[BERTology](https://huggingface.co/transformers/bertology.html) is the nickname for the growing amount of BERT-related research.\n",
    "\n",
    "BERT trains a transformer model on two tasks:\n",
    "\n",
    "- Masked language model:\n",
    "\n",
    "    - 15% of the tokens' wordpieces are selected at the beginning.\n",
    "    - 80% of those are replaced with [MASK],\n",
    "    - 10% are replaced with a random token,\n",
    "    - 10% are kept intact.\n",
    "\n",
    "- Next sentence prediction:\n",
    "    - Are sentences A and B consecutive sentences?\n",
    "    - Generate 50-50%.\n",
    "    - Binary classification task.\n",
    "    \n",
    "\n",
    "### Training, Finetuning BERT\n",
    "\n",
    "- BERT models are (masked-)language models that were usually trained on large corporas.\n",
    "\n",
    "- e.g. BERT base model was trained on BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia.\n",
    "- vocab_size=30522 for BERT base \n",
    "\n",
    "#### Finetuning\n",
    "\n",
    "- Get a trained BERT model.\n",
    "- Add a small classification layer on top (typically a 2-layer MLP).\n",
    "- Train BERT along with the classification layer on an annotated dataset.\n",
    "- Much smaller than the data BERT was trained on\n",
    "- Another option: freeze BERT and train the classification layer only.\n",
    "    - Easier training regime.\n",
    "    - Smaller memory footprint.\n",
    "    - Worse performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6wM58yp3d_s"
   },
   "source": [
    "<img src=\"https://production-media.paperswithcode.com/methods/new_BERT_Overall.jpg\" alt=\"finetune\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WimJ7cD3d_s",
    "outputId": "465b09cb-4eb9-4370-efda-1c0c88d7fd06"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHAnZlRA3d_s"
   },
   "source": [
    "### WordPiece tokenizer\n",
    "- BERT has its own tokenizer\n",
    "- All inputs must be tokenized with BERT\n",
    "- You don't need to remove stopwords, lemmatize, preprocess the input for BERT\n",
    "\n",
    "- It is a middle ground between word and character tokenization.\n",
    "\n",
    "- Static vocabulary:\n",
    "    - Special tokens: [CLS], [SEP], [MASK], [UNK]\n",
    "    - It tokenizes everything, falling back to characters and [UNK] if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hnq5zE8Wf-_F",
    "outputId": "e1225cb4-4d56-4810-b977-6a5327d6ef78"
   },
   "outputs": [],
   "source": [
    "!pip3 install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkBZHPfqPwZ-"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load a BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"I love Python 🐍 and data analysis 📊!\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"There are black cats and black dogs.\", \"Another sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> [CLS] Sentence 1 [SEP] Sentence 2 [SEP]\n",
    "\n",
    "100: [UNK] (Unknown token)\n",
    "\n",
    "101: [CLS] (Classification Token)\n",
    "\n",
    "102: [SEP] (Separator Token): The [CLS] token is special in BERT as it is used to aggregate information from the entire sequence. Its output embedding (from the last layer of the model) is often used for classification tasks (e.g., sentiment analysis, sentence-pair classification).\n",
    "\n",
    "103: [MASK] (Masked Token)\n",
    "\n",
    "0: [PAD] (Padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tokenizer))\n",
    "print(len(tokenizer.get_vocab()))\n",
    "\n",
    "tokenizer.tokenize(\"His full name is Fyodor Mikhailovich Dostoevsky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have a look at how another tokeniser works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load a BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")  # The vinai/bertweet-base model does not use BertTokenizer. it uses a RoBERTa-like tokenizer => AutoTokenizer for simplicity\n",
    "\n",
    "text = \"I love Python 🐍 and data analysis 📊!\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "3459a07ff77442a0a99d62a564aeab5a",
      "7c1fa3d8b54f4499a16b37b941b856d3",
      "4cd5bef030644364ad11b5fee58e1279",
      "44de39b785d14456997e3cafd6aa7578",
      "e74e23913379453aa16931b744e2e2d8",
      "3a14450014e74d918381af193a4aade0",
      "21e12a93ca1040ee9c796a1bd1ddb690",
      "d5ca0736f19b43f48d995c66fe3a790b",
      "146565c18d7940358a93ac1f139e2bd0",
      "5e25007b6c2e49e8ae6f61c5b927c6c1",
      "59d7aa0205b1432f8e0e069df1de55bb",
      "8ea0dfe133984d8a82026d93d1aa2f7e",
      "f9432d8165854debaa7d0f33acf2f471",
      "2da8cfea31114cddb4bccf2a7a070442",
      "7100823ec0bb4137b918ef42b000a71f",
      "42b4e686cded4f98a8f75c028e008278",
      "45ea52ab0e3341f7820c404ef4538591",
      "2bc8e3b3cc9447c5baeb3e291ca59950",
      "c6de9018faa54c3191df2700d2bb2f2b",
      "f326ca5639e949e9bec56868fc153679",
      "802e81c53b4b470bb496bfc457df3913",
      "e4db997df90f459c9af94a29c99a5207",
      "c7f998f7f4f74e189b76e771f6626f53",
      "2053c0e273a14a5ca7181ef1d715da9b",
      "15798adc99b84a64bee5e2bf516d3479",
      "3173c3d5743a48d89df922c77991e941",
      "b7f63463a8de4bc5a52d6a03a57abcfa",
      "49b86b4023f447a38f4cd386348945da",
      "f869070b970744e8805c44e8ec57eedb",
      "0084f75d88624fc38d3f5ad29c6718a2",
      "8c2dd19ab40e40cdab1e0264bb3733b4",
      "a560cc0902d44a60a7e2eebf951249e5",
      "c9f9c38161214356b21d3a10fb04e655",
      "6ac1188056784b96b03c18af698a3555",
      "c0137e3e2bd04202819a245bd779a172",
      "51d17cbe78904d81883dfb1a6c376736",
      "1cab0d74c9a9497296c05768cf00f236",
      "c5a99c03a661472a8528ac63006bd054",
      "984ed9f1ef754c938a900f48d11279a1",
      "5c29713b593a4086948e4fe12824bb62",
      "dabe388568ab4603a8507fca7d1ae509",
      "3d72d47fb5554cebbba3a299aa42eadf",
      "bb6eb80a86d94015b765c39913a3da4a",
      "e4fafd7a57704de18116e8f917f6b0b9"
     ]
    },
    "id": "__eq23ZTP21d",
    "outputId": "be2e99e5-0bfe-49d9-a9ff-7d9b63fb5bb4"
   },
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6crEZat3d_s",
    "outputId": "6e41eecc-7873-47ce-d6de-7b79920d71cd"
   },
   "outputs": [],
   "source": [
    "print(type(tokenizer))\n",
    "print(len(tokenizer.get_vocab()))\n",
    "\n",
    "tokenizer.tokenize(\"His full name is Fyodor Mikhailovich Dostoevsky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsDuwhJl3d_s",
    "outputId": "f9a3a9d8-c561-422c-dc21-47f4305f339d"
   },
   "outputs": [],
   "source": [
    "tokenizer(\"There are black cats and black dogs.\", \"Another sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-31r_6N3d_s"
   },
   "source": [
    "### Train a BertForSequenceClassification model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieWp80HC3d_t"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AutoModelForSequenceClassification, TrainingArguments, RobertaForSequenceClassification, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjbS4v-E3d_t"
   },
   "source": [
    "__BertForSequenceClassification__ is a helper class to train transformer-based BERT models. It puts a classification layer on top of a pretrained model.\n",
    "\n",
    "Read more in the documentation: https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "9cb3c33c775646ad969bf63742aac67c",
      "3a8c5d093fcd4ce7bc45af7cbb574d4d",
      "117939875677424c9654ba2659fc2afd",
      "eaad47593aa74e78afd8bd4f59d275b8",
      "0d2d068d26a149bb8dc313869d383b18",
      "c0cf938381f648bb80c3fba33aedcfed",
      "3ff241b617a34ff2ae37e965c62c1692",
      "ef7df33e327b4f1b82b9f9ed5aa956d6",
      "52eb4b4f37794bbcb7be0affffe0434b",
      "c265a33272d94721a2ad0d16f1576e5a",
      "8ab0b04ab3614908b7d6b116e6c4e1eb"
     ]
    },
    "id": "nNitpQlH3d_t",
    "outputId": "80c065b3-3a24-48d2-93f0-0a00dd84e97e"
   },
   "outputs": [],
   "source": [
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "#_ = model.to(device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2)\n",
    "_ = model.to(device)\n",
    "\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
    "#_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOOymZT0ZNs9"
   },
   "outputs": [],
   "source": [
    "# We only want to finetune the classification layer on top of BERT\n",
    "for p in model.base_model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.classifier.parameters():\n",
    "    print(p.requires_grad)  # Check trainable status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSSlbI6F3d_t",
    "outputId": "1830a80b-eb94-48ae-9119-91adb4a63a31"
   },
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print(f\"The BERT model has {len(params)} different named parameters.\")\n",
    "\n",
    "print(\"==== Embedding Layer ====\\n\")\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(f\"{p[0]} {str(tuple(p[1].size()))}\")\n",
    "\n",
    "print(\"\\n==== First Transformer Encoder Block ====\\n\")  \n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(f\"{p[0]} {str(tuple(p[1].size()))}\")\n",
    "\n",
    "print(\"\\n==== Output Layer ====\\n\")\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(f\"{p[0]} {str(tuple(p[1].size()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWfRwslX3d_t"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "#weights = torch.Tensor([1, 2])\n",
    "#criterion = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzJBSYBy3d_t",
    "outputId": "fd1dc375-7e42-4a6b-fe9f-3adfb4afcbda"
   },
   "outputs": [],
   "source": [
    "tr_data_loader, val_data_loader = prepare_dataloader_with_padding(\n",
    "    tr_data, val_data, word_to_ix\n",
    ")\n",
    "\n",
    "train_iterator, valid_iterator = create_dataloader_iterators_with_padding(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qw2l_Idk3d_t",
    "outputId": "fca7bd8d-7a36-4b93-b9d2-1ebeeb30c3dd"
   },
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_prec = 0\n",
    "    train_epoch_recall = 0\n",
    "    train_epoch_fscore = 0\n",
    "    model.train()\n",
    "\n",
    "    # We use our own iterator but now use the raw texts instead of the ID tokens\n",
    "    for train_batch in train_iterator:\n",
    "        labels = train_batch[1]\n",
    "        texts = train_batch[3]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # We use BERT's own tokenizer on raw texts\n",
    "        # Check the documentation: https://huggingface.co/transformers/main_classes/tokenizer.html\n",
    "        encoded = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # BERT converts texts into IDs of its own vocabulary\n",
    "        input_ids = encoded[\"input_ids\"].to(device)\n",
    "        # Mask to avoid performing attention on padding token indices.\n",
    "        attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Run the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs[0] #negative log likelihood loss\n",
    "\n",
    "\n",
    "        predictions = outputs[1]\n",
    "        #print(predictions)\n",
    "        prec, recall, fscore = calculate_performance(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_prec += prec.item()\n",
    "        train_epoch_recall += recall.item()\n",
    "        train_epoch_fscore += fscore.item()\n",
    "\n",
    "    train_loss = train_epoch_loss / len(train_iterator)\n",
    "    train_prec = train_epoch_prec / len(train_iterator)\n",
    "    train_rec = train_epoch_recall / len(train_iterator)\n",
    "    train_fscore = train_epoch_fscore / len(train_iterator)\n",
    "\n",
    "    # And validate your model on the validation set\n",
    "    valid_epoch_loss = 0\n",
    "    valid_epoch_prec = 0\n",
    "    valid_epoch_recall = 0\n",
    "    valid_epoch_fscore = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for valid_batch in valid_iterator:\n",
    "            labels = valid_batch[1]\n",
    "            texts = valid_batch[3]\n",
    "\n",
    "            encoded = tokenizer(\n",
    "                texts,\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            input_ids = encoded[\"input_ids\"].to(device)\n",
    "            attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            predictions = outputs[1]\n",
    "            prec, recall, fscore = calculate_performance(predictions, labels)\n",
    "\n",
    "            # We add batch-wise loss to the epoch-wise loss\n",
    "            valid_epoch_loss += loss.item()\n",
    "            valid_epoch_prec += prec.item()\n",
    "            valid_epoch_recall += recall.item()\n",
    "            valid_epoch_fscore += fscore.item()\n",
    "\n",
    "    valid_loss = valid_epoch_loss / len(valid_iterator)\n",
    "    valid_prec = valid_epoch_prec / len(valid_iterator)\n",
    "    valid_rec = valid_epoch_recall / len(valid_iterator)\n",
    "    valid_fscore = valid_epoch_fscore / len(valid_iterator)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(\n",
    "        f\"\\tTrain Loss: {train_loss:.3f} | Train Prec: {train_prec*100:.2f}% | Train Rec: {train_rec*100:.2f}% | Train Fscore: {train_fscore*100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"\\t Val. Loss: {valid_loss:.3f} |  Val Prec: {valid_prec*100:.2f}% | Val Rec: {valid_rec*100:.2f}% | Val Fscore: {valid_fscore*100:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJhkftgRnPfF"
   },
   "source": [
    "## Same experiment with HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will also look at how you can track your experiments with [mlflow](https://mlflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjO27_TGrNbs",
    "outputId": "20555f09-41da-4e2d-c509-0eec88675d27"
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32u3e_YVxT47",
    "outputId": "6373e936-55cc-48d5-f131-4a759bf3feef"
   },
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "transformers.__version__, accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmaqPsaT3d_t",
    "outputId": "9c99606e-38e0-48bd-8aec-fa2edfc5c46c"
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGh81QfDn579"
   },
   "source": [
    "Check the train and val data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "wTsbwgEsnaXt",
    "outputId": "d3f5ca87-2bd8-4b2b-ad58-c473544f79cc"
   },
   "outputs": [],
   "source": [
    "tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "VEFzyEKsn-wc",
    "outputId": "72f95023-e171-439f-b1c1-323668cc2e70"
   },
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7PL6IcRoQeB"
   },
   "outputs": [],
   "source": [
    "#convert a df column into a list of strings\n",
    "train_texts = tr_data.tweet.tolist()\n",
    "\n",
    "#convert a df column into a list of strings\n",
    "train_labels = tr_data.label.tolist()\n",
    "\n",
    "#convert a df column into a list of strings\n",
    "val_texts = val_data.tweet.tolist()\n",
    "\n",
    "#convert a df column into a list of strings\n",
    "val_labels = val_data.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOsNavpBowdq"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zi0o8GfTo0do"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsBVoBCjpF9s"
   },
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BskU_jlPpUrd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THBl7tpJ3py2"
   },
   "source": [
    "Now, we finetune our BERT model with different hyperparameters. Before we had `batch_size=64`, default batch size in the HugggingFace class `transformers.TrainingArguments`is 8. We also change the learnung rate.\n",
    "\n",
    "##### Change of hyperparameters\n",
    "- `batch_size=8`\n",
    "- `learning_rate=5e-5`\n",
    "##### Keep track of experiments with Weights & Biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you get an error similar to `ImportError: Using the Trainer with PyTorch requires accelerate>=0.20.1: Please run pip install transformers[torch] or pip install accelerate -U` when running code on the colab, please make sure you run the command `!pip install accelerate -U`. After that do the following:\n",
    "1. In the top menu click **Runtime** → **Restart Runtime**\n",
    "2. Do not rerun any cells with !pip install in them\n",
    "3. Rerun all the other code cells that refer to the experiment using Huggingface and you should be good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")  # Format: YYYYMMDD\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444,
     "referenced_widgets": [
      "bedd05a3dcbb4a90bbaaff13da1c0d55",
      "4765f41c37a143ba955a1fb03434b6cd",
      "4b8bd74d2b824ebb95d927efeda3b380",
      "12b7833abd174d00a552ce1ffcc12cba",
      "c6e84c2523b040b3ac7f37f376b56e5d",
      "27f0c4c773e841d0ad3fd5ca4578387f",
      "994b59e22e78433ca5abd14157557e2c",
      "74d80fa96e1547c1bd4e0991fd02d2a7",
      "a58e61a346bc47f7bc4125de08fe9f90",
      "e6af4d8fe63d4cb987fbf3dcb818f232",
      "708621a183564cc492e3e31221f09ea3",
      "a690261e4b3f427d8a09ff92d8469714",
      "06ae4a2c9bff449a96469ca79c4f6f6f",
      "648d768da4c74ca68fe1622269cdf08a",
      "b9876923900640b39c449dc83328e88c",
      "c3f74e8f21c84c4380a8c978ab608b22",
      "5797a82c4e3844c8be1fe9b75e97e54c",
      "b0f6dedbc1794b1ab53a0e8f7c7f0151",
      "85a8c21fd9ed46459dd055cd54647cec",
      "73cbc3d4f873410b95e5c10de91590c6",
      "5bcdef7aa0eb4ea384334d03f00415e6",
      "f7eaf6f2238143d1a46cd2c083c97f95",
      "9a66c855f00449c08111d8f52eecef1a",
      "eb3008aa2bec4526a88ccee75b493b30",
      "5c50ced65df84dbda3cf54a5cca0f837",
      "39240fd76ca140eeae24ca4648a835ef",
      "dd8f1c9851bd45c1b46bc2c932307c2e",
      "5dbfba30baad4c919daf14275963b93a",
      "db0c0de1b46e446084ee397a8acd80f6",
      "b4c891e1590e498483757ed001c63f2a",
      "4d85c970d7d64ed2bddfe8ae25bdff5c",
      "044657a7e9f04389bd52da3688e659db",
      "5406f6dd96cc4e76aa3ff3bdc957a21c",
      "9e0ad7e6300044d59b637cb1c913718f",
      "62b5648966e64af6a0b7098244e95898",
      "2863cf99a4c94403970773aae953a77b",
      "a242cf037c6e446f9f33fc01f25fa97e",
      "be8397673e9b4fecbb404fe0b898a61c",
      "82f20a9a535340b281c1d5883ff22f78",
      "b094b0688076455e89d671010561a823",
      "2c04580fc55844878dfb819129cc4159",
      "df04aae002a8427dbbf095fa4e83a3ee",
      "9f2d1f3c0e064c06b1e1d823b1200396",
      "40ed48da1f6b40bc923fe0b005618c9d",
      "c5b63442c79f4f1098135ba291c75ac4",
      "43d5518c9522411180d5b935694a99ba",
      "98ce9422525e40f0be280ed8579432dc",
      "463212231f8848cca4e4a4e90d18c61a",
      "0e15f6fd75974415989ce53e7e05904a",
      "c79ae4ad113a434c948e5137a79fcad8",
      "c82059cc49564e9991483f1e0d5a6b1b",
      "7f1430bfe5e34137a8f18babd624c7ee",
      "38b0cb2f897d4150846c1701250d7d81",
      "583969762b8348f49e085414635695d6",
      "f51c7658838541089f4719fc6ec54c2e"
     ]
    },
    "id": "9UR9RHK_p54R",
    "outputId": "02ef41fe-82b5-420f-eada-d4354722fd75"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"bert-finetuning\", name=f\"bert-base-uncased-semeval-{current_date}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results_bertbaseuncased_semeval_{current_date}\",\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    learning_rate=5e-5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=f\"./logs_bertbaseuncased_semeval_{current_date}\",            # directory for storing logs\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=False,\n",
    "    logging_steps=10,\n",
    "    metric_for_best_model='eval_loss', \n",
    "    report_to=\"wandb\"\n",
    "    )\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Early stopping with patience of 3\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Log evaluation results to wandb\n",
    "wandb.log(results)\n",
    "\n",
    "trainer.save_model(f\"./saved_model_bertbaseuncased_semeval_{current_date}\")\n",
    "\n",
    "# End the wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Create Assignment",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0084f75d88624fc38d3f5ad29c6718a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "044657a7e9f04389bd52da3688e659db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06ae4a2c9bff449a96469ca79c4f6f6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5797a82c4e3844c8be1fe9b75e97e54c",
      "placeholder": "​",
      "style": "IPY_MODEL_b0f6dedbc1794b1ab53a0e8f7c7f0151",
      "value": "Downloading artifacts: 100%"
     }
    },
    "0d2d068d26a149bb8dc313869d383b18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e15f6fd75974415989ce53e7e05904a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "117939875677424c9654ba2659fc2afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef7df33e327b4f1b82b9f9ed5aa956d6",
      "max": 542529064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52eb4b4f37794bbcb7be0affffe0434b",
      "value": 542529064
     }
    },
    "12b7833abd174d00a552ce1ffcc12cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6af4d8fe63d4cb987fbf3dcb818f232",
      "placeholder": "​",
      "style": "IPY_MODEL_708621a183564cc492e3e31221f09ea3",
      "value": " 7/7 [00:05&lt;00:00,  1.24it/s]"
     }
    },
    "146565c18d7940358a93ac1f139e2bd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15798adc99b84a64bee5e2bf516d3479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0084f75d88624fc38d3f5ad29c6718a2",
      "max": 1078931,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c2dd19ab40e40cdab1e0264bb3733b4",
      "value": 1078931
     }
    },
    "1cab0d74c9a9497296c05768cf00f236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb6eb80a86d94015b765c39913a3da4a",
      "placeholder": "​",
      "style": "IPY_MODEL_e4fafd7a57704de18116e8f917f6b0b9",
      "value": " 2.91M/2.91M [00:00&lt;00:00, 8.82MB/s]"
     }
    },
    "2053c0e273a14a5ca7181ef1d715da9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49b86b4023f447a38f4cd386348945da",
      "placeholder": "​",
      "style": "IPY_MODEL_f869070b970744e8805c44e8ec57eedb",
      "value": "Downloading (…)solve/main/bpe.codes: 100%"
     }
    },
    "21e12a93ca1040ee9c796a1bd1ddb690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27f0c4c773e841d0ad3fd5ca4578387f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2863cf99a4c94403970773aae953a77b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c04580fc55844878dfb819129cc4159",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df04aae002a8427dbbf095fa4e83a3ee",
      "value": 7
     }
    },
    "2bc8e3b3cc9447c5baeb3e291ca59950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c04580fc55844878dfb819129cc4159": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2da8cfea31114cddb4bccf2a7a070442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6de9018faa54c3191df2700d2bb2f2b",
      "max": 843438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f326ca5639e949e9bec56868fc153679",
      "value": 843438
     }
    },
    "3173c3d5743a48d89df922c77991e941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a560cc0902d44a60a7e2eebf951249e5",
      "placeholder": "​",
      "style": "IPY_MODEL_c9f9c38161214356b21d3a10fb04e655",
      "value": " 1.08M/1.08M [00:00&lt;00:00, 5.44MB/s]"
     }
    },
    "3459a07ff77442a0a99d62a564aeab5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c1fa3d8b54f4499a16b37b941b856d3",
       "IPY_MODEL_4cd5bef030644364ad11b5fee58e1279",
       "IPY_MODEL_44de39b785d14456997e3cafd6aa7578"
      ],
      "layout": "IPY_MODEL_e74e23913379453aa16931b744e2e2d8"
     }
    },
    "38b0cb2f897d4150846c1701250d7d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39240fd76ca140eeae24ca4648a835ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_044657a7e9f04389bd52da3688e659db",
      "placeholder": "​",
      "style": "IPY_MODEL_5406f6dd96cc4e76aa3ff3bdc957a21c",
      "value": " 7/7 [00:08&lt;00:00,  1.49s/it]"
     }
    },
    "3a14450014e74d918381af193a4aade0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a8c5d093fcd4ce7bc45af7cbb574d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0cf938381f648bb80c3fba33aedcfed",
      "placeholder": "​",
      "style": "IPY_MODEL_3ff241b617a34ff2ae37e965c62c1692",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "3d72d47fb5554cebbba3a299aa42eadf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ff241b617a34ff2ae37e965c62c1692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40ed48da1f6b40bc923fe0b005618c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42b4e686cded4f98a8f75c028e008278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43d5518c9522411180d5b935694a99ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c79ae4ad113a434c948e5137a79fcad8",
      "placeholder": "​",
      "style": "IPY_MODEL_c82059cc49564e9991483f1e0d5a6b1b",
      "value": "Downloading artifacts: 100%"
     }
    },
    "44de39b785d14456997e3cafd6aa7578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e25007b6c2e49e8ae6f61c5b927c6c1",
      "placeholder": "​",
      "style": "IPY_MODEL_59d7aa0205b1432f8e0e069df1de55bb",
      "value": " 558/558 [00:00&lt;00:00, 36.7kB/s]"
     }
    },
    "45ea52ab0e3341f7820c404ef4538591": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "463212231f8848cca4e4a4e90d18c61a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_583969762b8348f49e085414635695d6",
      "placeholder": "​",
      "style": "IPY_MODEL_f51c7658838541089f4719fc6ec54c2e",
      "value": " 7/7 [00:05&lt;00:00,  1.25it/s]"
     }
    },
    "4765f41c37a143ba955a1fb03434b6cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27f0c4c773e841d0ad3fd5ca4578387f",
      "placeholder": "​",
      "style": "IPY_MODEL_994b59e22e78433ca5abd14157557e2c",
      "value": "Downloading artifacts: 100%"
     }
    },
    "49b86b4023f447a38f4cd386348945da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b8bd74d2b824ebb95d927efeda3b380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74d80fa96e1547c1bd4e0991fd02d2a7",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a58e61a346bc47f7bc4125de08fe9f90",
      "value": 7
     }
    },
    "4cd5bef030644364ad11b5fee58e1279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5ca0736f19b43f48d995c66fe3a790b",
      "max": 558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_146565c18d7940358a93ac1f139e2bd0",
      "value": 558
     }
    },
    "4d85c970d7d64ed2bddfe8ae25bdff5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51d17cbe78904d81883dfb1a6c376736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dabe388568ab4603a8507fca7d1ae509",
      "max": 2912687,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d72d47fb5554cebbba3a299aa42eadf",
      "value": 2912687
     }
    },
    "52eb4b4f37794bbcb7be0affffe0434b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5406f6dd96cc4e76aa3ff3bdc957a21c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5797a82c4e3844c8be1fe9b75e97e54c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "583969762b8348f49e085414635695d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59d7aa0205b1432f8e0e069df1de55bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bcdef7aa0eb4ea384334d03f00415e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c29713b593a4086948e4fe12824bb62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c50ced65df84dbda3cf54a5cca0f837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4c891e1590e498483757ed001c63f2a",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d85c970d7d64ed2bddfe8ae25bdff5c",
      "value": 7
     }
    },
    "5dbfba30baad4c919daf14275963b93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e25007b6c2e49e8ae6f61c5b927c6c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62b5648966e64af6a0b7098244e95898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82f20a9a535340b281c1d5883ff22f78",
      "placeholder": "​",
      "style": "IPY_MODEL_b094b0688076455e89d671010561a823",
      "value": "Downloading artifacts: 100%"
     }
    },
    "648d768da4c74ca68fe1622269cdf08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85a8c21fd9ed46459dd055cd54647cec",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73cbc3d4f873410b95e5c10de91590c6",
      "value": 7
     }
    },
    "6ac1188056784b96b03c18af698a3555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0137e3e2bd04202819a245bd779a172",
       "IPY_MODEL_51d17cbe78904d81883dfb1a6c376736",
       "IPY_MODEL_1cab0d74c9a9497296c05768cf00f236"
      ],
      "layout": "IPY_MODEL_c5a99c03a661472a8528ac63006bd054"
     }
    },
    "708621a183564cc492e3e31221f09ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7100823ec0bb4137b918ef42b000a71f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_802e81c53b4b470bb496bfc457df3913",
      "placeholder": "​",
      "style": "IPY_MODEL_e4db997df90f459c9af94a29c99a5207",
      "value": " 843k/843k [00:00&lt;00:00, 4.13MB/s]"
     }
    },
    "73cbc3d4f873410b95e5c10de91590c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74d80fa96e1547c1bd4e0991fd02d2a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c1fa3d8b54f4499a16b37b941b856d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a14450014e74d918381af193a4aade0",
      "placeholder": "​",
      "style": "IPY_MODEL_21e12a93ca1040ee9c796a1bd1ddb690",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "7f1430bfe5e34137a8f18babd624c7ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "802e81c53b4b470bb496bfc457df3913": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82f20a9a535340b281c1d5883ff22f78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85a8c21fd9ed46459dd055cd54647cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ab0b04ab3614908b7d6b116e6c4e1eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c2dd19ab40e40cdab1e0264bb3733b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ea0dfe133984d8a82026d93d1aa2f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9432d8165854debaa7d0f33acf2f471",
       "IPY_MODEL_2da8cfea31114cddb4bccf2a7a070442",
       "IPY_MODEL_7100823ec0bb4137b918ef42b000a71f"
      ],
      "layout": "IPY_MODEL_42b4e686cded4f98a8f75c028e008278"
     }
    },
    "984ed9f1ef754c938a900f48d11279a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ce9422525e40f0be280ed8579432dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f1430bfe5e34137a8f18babd624c7ee",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38b0cb2f897d4150846c1701250d7d81",
      "value": 7
     }
    },
    "994b59e22e78433ca5abd14157557e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a66c855f00449c08111d8f52eecef1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb3008aa2bec4526a88ccee75b493b30",
       "IPY_MODEL_5c50ced65df84dbda3cf54a5cca0f837",
       "IPY_MODEL_39240fd76ca140eeae24ca4648a835ef"
      ],
      "layout": "IPY_MODEL_dd8f1c9851bd45c1b46bc2c932307c2e"
     }
    },
    "9cb3c33c775646ad969bf63742aac67c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a8c5d093fcd4ce7bc45af7cbb574d4d",
       "IPY_MODEL_117939875677424c9654ba2659fc2afd",
       "IPY_MODEL_eaad47593aa74e78afd8bd4f59d275b8"
      ],
      "layout": "IPY_MODEL_0d2d068d26a149bb8dc313869d383b18"
     }
    },
    "9e0ad7e6300044d59b637cb1c913718f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62b5648966e64af6a0b7098244e95898",
       "IPY_MODEL_2863cf99a4c94403970773aae953a77b",
       "IPY_MODEL_a242cf037c6e446f9f33fc01f25fa97e"
      ],
      "layout": "IPY_MODEL_be8397673e9b4fecbb404fe0b898a61c"
     }
    },
    "9f2d1f3c0e064c06b1e1d823b1200396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a242cf037c6e446f9f33fc01f25fa97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f2d1f3c0e064c06b1e1d823b1200396",
      "placeholder": "​",
      "style": "IPY_MODEL_40ed48da1f6b40bc923fe0b005618c9d",
      "value": " 7/7 [00:05&lt;00:00,  1.20it/s]"
     }
    },
    "a560cc0902d44a60a7e2eebf951249e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58e61a346bc47f7bc4125de08fe9f90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a690261e4b3f427d8a09ff92d8469714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06ae4a2c9bff449a96469ca79c4f6f6f",
       "IPY_MODEL_648d768da4c74ca68fe1622269cdf08a",
       "IPY_MODEL_b9876923900640b39c449dc83328e88c"
      ],
      "layout": "IPY_MODEL_c3f74e8f21c84c4380a8c978ab608b22"
     }
    },
    "b094b0688076455e89d671010561a823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0f6dedbc1794b1ab53a0e8f7c7f0151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4c891e1590e498483757ed001c63f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7f63463a8de4bc5a52d6a03a57abcfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9876923900640b39c449dc83328e88c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bcdef7aa0eb4ea384334d03f00415e6",
      "placeholder": "​",
      "style": "IPY_MODEL_f7eaf6f2238143d1a46cd2c083c97f95",
      "value": " 7/7 [00:06&lt;00:00,  1.07it/s]"
     }
    },
    "bb6eb80a86d94015b765c39913a3da4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be8397673e9b4fecbb404fe0b898a61c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bedd05a3dcbb4a90bbaaff13da1c0d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4765f41c37a143ba955a1fb03434b6cd",
       "IPY_MODEL_4b8bd74d2b824ebb95d927efeda3b380",
       "IPY_MODEL_12b7833abd174d00a552ce1ffcc12cba"
      ],
      "layout": "IPY_MODEL_c6e84c2523b040b3ac7f37f376b56e5d"
     }
    },
    "c0137e3e2bd04202819a245bd779a172": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_984ed9f1ef754c938a900f48d11279a1",
      "placeholder": "​",
      "style": "IPY_MODEL_5c29713b593a4086948e4fe12824bb62",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "c0cf938381f648bb80c3fba33aedcfed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c265a33272d94721a2ad0d16f1576e5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3f74e8f21c84c4380a8c978ab608b22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a99c03a661472a8528ac63006bd054": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b63442c79f4f1098135ba291c75ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43d5518c9522411180d5b935694a99ba",
       "IPY_MODEL_98ce9422525e40f0be280ed8579432dc",
       "IPY_MODEL_463212231f8848cca4e4a4e90d18c61a"
      ],
      "layout": "IPY_MODEL_0e15f6fd75974415989ce53e7e05904a"
     }
    },
    "c6de9018faa54c3191df2700d2bb2f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e84c2523b040b3ac7f37f376b56e5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c79ae4ad113a434c948e5137a79fcad8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7f998f7f4f74e189b76e771f6626f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2053c0e273a14a5ca7181ef1d715da9b",
       "IPY_MODEL_15798adc99b84a64bee5e2bf516d3479",
       "IPY_MODEL_3173c3d5743a48d89df922c77991e941"
      ],
      "layout": "IPY_MODEL_b7f63463a8de4bc5a52d6a03a57abcfa"
     }
    },
    "c82059cc49564e9991483f1e0d5a6b1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f9c38161214356b21d3a10fb04e655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5ca0736f19b43f48d995c66fe3a790b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dabe388568ab4603a8507fca7d1ae509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db0c0de1b46e446084ee397a8acd80f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd8f1c9851bd45c1b46bc2c932307c2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df04aae002a8427dbbf095fa4e83a3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4db997df90f459c9af94a29c99a5207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4fafd7a57704de18116e8f917f6b0b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6af4d8fe63d4cb987fbf3dcb818f232": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e74e23913379453aa16931b744e2e2d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaad47593aa74e78afd8bd4f59d275b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c265a33272d94721a2ad0d16f1576e5a",
      "placeholder": "​",
      "style": "IPY_MODEL_8ab0b04ab3614908b7d6b116e6c4e1eb",
      "value": " 543M/543M [00:32&lt;00:00, 29.2MB/s]"
     }
    },
    "eb3008aa2bec4526a88ccee75b493b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dbfba30baad4c919daf14275963b93a",
      "placeholder": "​",
      "style": "IPY_MODEL_db0c0de1b46e446084ee397a8acd80f6",
      "value": "Downloading artifacts: 100%"
     }
    },
    "ef7df33e327b4f1b82b9f9ed5aa956d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f326ca5639e949e9bec56868fc153679": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f51c7658838541089f4719fc6ec54c2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7eaf6f2238143d1a46cd2c083c97f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f869070b970744e8805c44e8ec57eedb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9432d8165854debaa7d0f33acf2f471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45ea52ab0e3341f7820c404ef4538591",
      "placeholder": "​",
      "style": "IPY_MODEL_2bc8e3b3cc9447c5baeb3e291ca59950",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
